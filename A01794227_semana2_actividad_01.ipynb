{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "759SG4TyfbUn",
        "Zj-h4drXD-X9",
        "BY6yifxscfrx",
        "k_ewoagic5jc",
        "70StdqAZa9E9"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Maestría en Inteligencia Artificial Aplicada**\n",
        "##**Curso: Procesamiento de Lenguaje Natural (NLP)**\n",
        "###Tecnológico de Monterrey\n",
        "###Prof Luis Eduardo Falcón Morales\n",
        "###Alumno: Ricardo Sinuhé Acevedo Baleón\n",
        "###Matrícula: A01794227\n",
        "\n",
        "## **Actividad de la Semana 02**\n",
        "###**Introducción al procesamiento de texto.**"
      ],
      "metadata": {
        "id": "759SG4TyfbUn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta actividad deberás utilizar los datos del siguiente archivo que se encuentra en Canvas:\n",
        "\n",
        "MNA_NLP_semana_02_Actividad_datos.txt\n",
        "\n",
        "El archivo contiene comentarios en inglés sobre servicios de comida de la página de Yelp: https://www.yelp.com/ . \n",
        "\n",
        "Son mil comentarios y forman parte del conjunto de datos que se encuentra en el Machine Learning Repository de la UCI, llamado \"Sentiment Labelled Sentences\": https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences#\n"
      ],
      "metadata": {
        "id": "6ue1YAKx3XDo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Parte 1. Cargamos los datos.**   "
      ],
      "metadata": {
        "id": "Zj-h4drXD-X9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cargar los datos del archivo indicado y obtener una lista de longitud de 1000 strings/comentarios. \n",
        "\n",
        "Por el momento solamente requerimos las bibliotecas de Numpy y re, para el manejo de los arreglos y de las expresiones regulares en Python.\n",
        "\n",
        "En particular, no necesitarás en esta actividad la biblioteca de Pandas.\n",
        "\n",
        "###**NOTA: En esta actividad no debes importar nada más, con estas dos bibliotecas será *suficiente*.**"
      ],
      "metadata": {
        "id": "BY6yifxscfrx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np    # importamos Numpy para el manejo de los arreglos.\n",
        "import re             # importamos re para el manejo de las expresiones regulares."
      ],
      "metadata": {
        "id": "OJ26dAfhdFnf"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejecuta las siguientes instrucciones para cargar la información del achivo dado:\n",
        "\n",
        "with open('MNA_NLP_semana_02_Actividad_datos.txt',        # puedes actualizar la ruta a tu archivo, en dado caso.\n",
        "          mode='r',     # abrimos el archivo en modo lectura.\n",
        "          ) as f:\n",
        "    docs = f.readlines()    # separamos cada comentario por líneas\n",
        "\n",
        "f.close()  # ya que tenemos la información en la variable docs, cerramos el archivo"
      ],
      "metadata": {
        "id": "QHUmJyjDdGNP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(docs) == list   # Verifica que tu variable \"docs\" es una lista"
      ],
      "metadata": {
        "id": "L6WzrSrodG-Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6aa34e38-3613-4c5f-90fa-33a4b2df4428"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(docs)==1000  # verifica que la longitud de \"docs\" es de mil comentarios."
      ],
      "metadata": {
        "id": "QIK1u9WS2FtS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21e41908-71f9-4b83-a9f3-b44edb09759a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs[0:10]     # observa algunos de los primeros comentarios"
      ],
      "metadata": {
        "id": "9AMLIfQvJqNZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1268e1d1-678f-45c4-f57f-9a62ef158b9f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Wow... Loved this place.\\n',\n",
              " 'Crust is not good.\\n',\n",
              " 'Not tasty and the texture was just nasty.\\n',\n",
              " 'Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.\\n',\n",
              " 'The selection on the menu was great and so were the prices.\\n',\n",
              " 'Now I am getting angry and I want my damn pho.\\n',\n",
              " \"Honeslty it didn't taste THAT fresh.)\\n\",\n",
              " 'The potatoes were like rubber and you could tell they had been made up ahead of time being kept under a warmer.\\n',\n",
              " 'The fries were great too.\\n',\n",
              " 'A great touch.\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Parte 2: sección de preguntas (regex).**   \n"
      ],
      "metadata": {
        "id": "k_ewoagic5jc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Instrucciones:**\n",
        "\n",
        "###**A continuación deberás contestar cada una de las preguntas que te piden usando expresiones regulares (regex).**\n",
        "\n",
        "###**Por el momento no hay restricción en cuanto al número de líneas de código que agregues, pero trata de incluir las mínimas posibles.**"
      ],
      "metadata": {
        "id": "X-eMJa3DFCIV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 1.** \n",
        "\n",
        "Busca y elimina todos los saltos de línea '\\n' que se encuentran al final de cada comentario. \n",
        "\n",
        "Una vez finalizado, imprime los primeros 10 comentarios del resultado obtenido.\n"
      ],
      "metadata": {
        "id": "78nJMemzn5a5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lista_con_saltos = docs\n",
        "lista_sin_saltos = [elemento.replace('\\n', '') for elemento in lista_con_saltos]"
      ],
      "metadata": {
        "id": "PwbYYIuZn8pE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lista_sin_saltos[0:10]"
      ],
      "metadata": {
        "id": "j-0qeh2Jn8l1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91e84618-e24b-4b90-f749-e0c999712dd0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Wow... Loved this place.',\n",
              " 'Crust is not good.',\n",
              " 'Not tasty and the texture was just nasty.',\n",
              " 'Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.',\n",
              " 'The selection on the menu was great and so were the prices.',\n",
              " 'Now I am getting angry and I want my damn pho.',\n",
              " \"Honeslty it didn't taste THAT fresh.)\",\n",
              " 'The potatoes were like rubber and you could tell they had been made up ahead of time being kept under a warmer.',\n",
              " 'The fries were great too.',\n",
              " 'A great touch.']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 2.**  \n",
        "\n",
        "Busca e imprime todas las palabras que terminan con dos o más signos de admiración seguidos, por ejemplo \"!!!\". \n",
        "\n",
        "Debes imprimir tanto la palabra como la totalidad de signos de admiración que le siguen. \n",
        "\n",
        "Indica cuántos resultados obtuviste.\n",
        "\n"
      ],
      "metadata": {
        "id": "VWeKQC93ctEo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializa variables para contar el número total de líneas y signos de exclamación\n",
        "num_lineas = 0\n",
        "total_exclamaciones = 0\n",
        "\n",
        "# Abre el archivo en modo lectura ('r')\n",
        "with open('MNA_NLP_semana_02_Actividad_datos.txt', 'r') as archivo:\n",
        "    # Lee todas las líneas del archivo y las almacena en una lista\n",
        "    lineas = archivo.readlines()\n",
        "\n",
        "# Itera a través de cada línea del archivo\n",
        "for linea in lineas:\n",
        "    # Verifica si la línea termina con dos o más signos de exclamación\n",
        "    if linea.strip().endswith('!!'):\n",
        "        # Incrementa el contador de líneas\n",
        "        num_lineas += 1\n",
        "\n",
        "        # Cuenta el número de signos de exclamación en la línea\n",
        "        num_exclamaciones = linea.count('!')\n",
        "        total_exclamaciones += num_exclamaciones\n",
        "\n",
        "        # Imprime la línea y el número de signos de exclamación encontrados\n",
        "        print(f\"Línea {num_lineas}: {linea.strip()} ({num_exclamaciones} signos de exclamación)\")\n",
        "\n",
        "# Imprime el número total de líneas y signos de exclamación encontrados\n",
        "print(f\"Se encontraron {num_lineas} líneas con dos o más signos de exclamación.\")\n",
        "print(f\"Se encontraron un total de {total_exclamaciones} signos de exclamación en las líneas seleccionadas.\")"
      ],
      "metadata": {
        "id": "0p3kMXfddICc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa0ce9f3-23a8-4238-f3bb-c8855f889ab8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Línea 1: If you want a sandwich just go to any Firehouse!!!!! (5 signos de exclamación)\n",
            "Línea 2: This place receives stars for their APPETIZERS!!! (3 signos de exclamación)\n",
            "Línea 3: All I have to say is the food was amazing!!! (3 signos de exclamación)\n",
            "Línea 4: Best breakfast buffet!!! (3 signos de exclamación)\n",
            "Línea 5: Sooooo good!! (2 signos de exclamación)\n",
            "Línea 6: Don't do it!!!! (4 signos de exclamación)\n",
            "Línea 7: DELICIOUS!! (2 signos de exclamación)\n",
            "Línea 8: This is the place where I first had pho and it was amazing!! (2 signos de exclamación)\n",
            "Línea 9: Favorite place in town for shawarrrrrrma!!!!!! (6 signos de exclamación)\n",
            "Línea 10: First - the bathrooms at this location were dirty- Seat covers were not replenished & just plain yucky!!! (3 signos de exclamación)\n",
            "Línea 11: It was delicious!!! (3 signos de exclamación)\n",
            "Línea 12: Best tacos in town by far!! (2 signos de exclamación)\n",
            "Línea 13: We loved the biscuits!!! (3 signos de exclamación)\n",
            "Línea 14: Very disappointing!!! (3 signos de exclamación)\n",
            "Línea 15: A fantastic neighborhood gem !!! (3 signos de exclamación)\n",
            "Línea 16: Have been going since 2007 and every meal has been awesome!! (2 signos de exclamación)\n",
            "Línea 17: 2 Thumbs Up!! (2 signos de exclamación)\n",
            "Línea 18: A FLY was in my apple juice.. A FLY!!!!!!!! (8 signos de exclamación)\n",
            "Línea 19: This place is great!!!!!!!!!!!!!! (14 signos de exclamación)\n",
            "Línea 20: It was packed!! (2 signos de exclamación)\n",
            "Línea 21: The chips and sals a here is amazing!!!!!!!!!!!!!!!!!!! (19 signos de exclamación)\n",
            "Línea 22: This place lacked style!! (2 signos de exclamación)\n",
            "Línea 23: I was VERY disappointed!! (2 signos de exclamación)\n",
            "Se encontraron 23 líneas con dos o más signos de exclamación.\n",
            "Se encontraron un total de 98 signos de exclamación en las líneas seleccionadas.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SPVM1MCWdH6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 3.**  \n",
        "\n",
        "Busca e imprime todas las palabras que están escritas totalmente en mayúsculas. Cada coincidencia debe ser una sola palabra.\n",
        "\n",
        "Indica cuántas palabras encontraste.\n",
        "\n"
      ],
      "metadata": {
        "id": "-s3okBqL96TT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializa variables para contar el número total de líneas y signos de exclamación\n",
        "num_lineas = 0\n",
        "\n",
        "# Abre el archivo en modo lectura ('r')\n",
        "with open('MNA_NLP_semana_02_Actividad_datos.txt', 'r') as archivo:\n",
        "    # Lee todas las líneas del archivo y las almacena en una lista\n",
        "    lineas = archivo.readlines()\n",
        "\n",
        "# Itera a través de cada línea del archivo\n",
        "for linea in lineas:\n",
        "    # Verifica si la línea está completamente en mayúsculas\n",
        "    if linea.isupper():\n",
        "        # Incrementa el contador de líneas\n",
        "        num_lineas += 1\n",
        "\n",
        "        # Imprime la línea en mayúsculas\n",
        "        print(f\"Línea {num_lineas}: {linea.strip()}\")\n",
        "\n",
        "# Imprime el número total de líneas encontradas\n",
        "print(f\"Se encontraron {num_lineas} líneas completamente en mayúsculas.\")"
      ],
      "metadata": {
        "id": "yKHJkZKo_nW5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3dd0d9e4-cd67-45d5-cdd8-c5ea32bcb8da"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Línea 1: DELICIOUS!!\n",
            "Línea 2: RUDE & INCONSIDERATE MANAGEMENT.\n",
            "Línea 3: WILL NEVER EVER GO BACK AND HAVE TOLD MANY PEOPLE WHAT HAD HAPPENED.\n",
            "Línea 4: TOTAL WASTE OF TIME.\n",
            "Línea 5: AVOID THIS ESTABLISHMENT!\n",
            "Se encontraron 5 líneas completamente en mayúsculas.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L3q08aq69sNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 4.**  \n",
        "\n",
        "Busca e imprime los comentarios en donde todos los caracteres alfabéticos (letras) están en mayúsculas. \n",
        "\n",
        "Cada coincidencia encontrada debe ser todo el comentario/enunciado.\n",
        "\n",
        "Indica cuántos resultados obtuviste.\n"
      ],
      "metadata": {
        "id": "GX8eYyDoMZma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "with open('MNA_NLP_semana_02_Actividad_datos.txt', 'r') as f:\n",
        "    corpus = f.readlines()\n",
        "\n",
        "# Buscar comentarios en donde todas las palabras estén en mayúsculas\n",
        "count = 0\n",
        "for comment in corpus:\n",
        "    if comment.isupper():\n",
        "        print(comment)\n",
        "        count += 1\n",
        "\n",
        "print(f\"Se encontraron {count} resultados.\")"
      ],
      "metadata": {
        "id": "K8VuZxvTMYj6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2aa07dff-9422-4666-bc76-57e06cc2449f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DELICIOUS!!\n",
            "\n",
            "RUDE & INCONSIDERATE MANAGEMENT.\n",
            "\n",
            "WILL NEVER EVER GO BACK AND HAVE TOLD MANY PEOPLE WHAT HAD HAPPENED.\n",
            "\n",
            "TOTAL WASTE OF TIME.\n",
            "\n",
            "AVOID THIS ESTABLISHMENT!\n",
            "\n",
            "Se encontraron 5 resultados.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PmKgX7sCMcDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 5.**  \n",
        "\n",
        "Busca e imprime todas las palabras que tengan una vocal acentuada, del tipo á, é, í, ó, ú. \n",
        "\n",
        "Indica cuántos resultados obtuviste."
      ],
      "metadata": {
        "id": "a1i6qv7-McmU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Inicializa una lista para almacenar las palabras con vocales acentuadas\n",
        "palabras_con_acentos = []\n",
        "\n",
        "# Abre el archivo en modo lectura ('r')\n",
        "with open('MNA_NLP_semana_02_Actividad_datos.txt', 'r') as archivo:\n",
        "    # Lee todo el contenido del archivo y lo almacena en una cadena de texto\n",
        "    contenido = archivo.read()\n",
        "\n",
        "    # Busca todas las palabras que contengan una vocal acentuada y las almacena en la lista\n",
        "    palabras_con_acentos = re.findall(r'\\b\\w*[áéíóú]\\w*\\b', contenido)\n",
        "\n",
        "# Imprime la lista de palabras con vocales acentuadas\n",
        "print(\"Palabras con vocales acentuadas:\")\n",
        "for palabra in palabras_con_acentos:\n",
        "    print(palabra)\n",
        "\n",
        "# Imprime el número total de resultados encontrados\n",
        "print(f\"Se encontraron un total de {len(palabras_con_acentos)} palabras con vocales acentuadas.\")"
      ],
      "metadata": {
        "id": "nZZ5zKUOMeGD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ca029d6-ef06-4584-bdb9-b7b7b0fd4038"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palabras con vocales acentuadas:\n",
            "fiancé\n",
            "Café\n",
            "puréed\n",
            "Se encontraron un total de 3 palabras con vocales acentuadas.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l1mFvUEZMe8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 6.**  \n",
        "\n",
        "Busca e imprime todas las cantidades numéricas monetarias, enteras o con decimales, que inician con el símbolo $\\$$. \n",
        "\n",
        "Indica cuántos resultados obtuviste."
      ],
      "metadata": {
        "id": "ZmPiAI82Mfb3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Inicializa una lista para almacenar las cantidades monetarias\n",
        "cantidades_monetarias = []\n",
        "\n",
        "# Abre el archivo en modo lectura ('r')\n",
        "with open('MNA_NLP_semana_02_Actividad_datos.txt', 'r') as archivo:\n",
        "    # Lee todo el contenido del archivo y lo almacena en una cadena de texto\n",
        "    contenido = archivo.read()\n",
        "\n",
        "    # Busca todas las cantidades monetarias que inicien con el símbolo $ y las almacena en la lista\n",
        "    cantidades_monetarias = re.findall(r'\\$\\d+(?:\\.\\d+)?', contenido)\n",
        "\n",
        "# Imprime la lista de cantidades monetarias\n",
        "print(\"Cantidades monetarias encontradas:\")\n",
        "for cantidad in cantidades_monetarias:\n",
        "    print(cantidad)\n",
        "\n",
        "# Imprime el número total de resultados encontrados\n",
        "print(f\"Se encontraron un total de {len(cantidades_monetarias)} cantidades monetarias.\")"
      ],
      "metadata": {
        "id": "6vhe9-Y-MhL9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "300b728e-9e00-432d-e571-cf9617fc764c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidades monetarias encontradas:\n",
            "$20\n",
            "$4.00\n",
            "$17\n",
            "$3\n",
            "$35\n",
            "$7.85\n",
            "$12\n",
            "$11.99\n",
            "Se encontraron un total de 8 cantidades monetarias.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_t0a5xWDMhQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 7.**  \n",
        "\n",
        "Busca e imprime todas las palabras que sean variantes de la palabra \"love\", sin importar si incluyen mayúsculas o minúsculas, o la manera en que esté conjugada o alguna otra variación que se haga con dicha palabra.\n",
        "\n",
        "Indica cuántos resultados obtuviste."
      ],
      "metadata": {
        "id": "2j-HpvhwMhq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# leer archivo\n",
        "with open('MNA_NLP_semana_02_Actividad_datos.txt', 'r') as f:\n",
        "    texto = f.read()\n",
        "\n",
        "# buscar palabras que sean variantes de \"love\"\n",
        "palabras_love = re.findall(r'\\b\\w*love\\w*\\b', texto, flags=re.IGNORECASE)\n",
        "\n",
        "# imprimir resultados sin la palabra \"love\"\n",
        "print(\"Palabras que son variantes de 'love':\")\n",
        "for palabra in palabras_love:\n",
        "    if palabra.lower() != 'love':  # ignorar la palabra \"love\"\n",
        "        print(palabra)\n",
        "\n",
        "# cantidad de resultados sin contar la palabra \"love\"\n",
        "total_palabras = len([palabra for palabra in palabras_love if palabra.lower() != 'love'])\n",
        "print(\"Total de resultados encontrados: \", total_palabras)"
      ],
      "metadata": {
        "id": "kqqyRChVMjol",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c11c775-542b-46a6-fa1e-9deb70ac24f7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palabras que son variantes de 'love':\n",
            "Loved\n",
            "loved\n",
            "Loved\n",
            "loves\n",
            "LOVED\n",
            "lovers\n",
            "lovers\n",
            "loved\n",
            "loved\n",
            "loved\n",
            "loved\n",
            "LOVED\n",
            "lovely\n",
            "lovely\n",
            "lover\n",
            "loved\n",
            "gloves\n",
            "Total de resultados encontrados:  17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UXd0VQluMj_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 8.**  \n",
        "\n",
        "Busca e imprime todas las palabras, variantes de \"so\" y \"good\", que tengan dos o más \"o\" en \"so\" y 3 o más \"o\" en good. \n",
        "\n",
        "Indica cuántas encontraste.\n"
      ],
      "metadata": {
        "id": "Ctb-NTY3MkYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Inicializa una lista para almacenar las palabras que cumplen con los criterios\n",
        "palabras_encontradas = []\n",
        "\n",
        "# Abre el archivo en modo lectura ('r')\n",
        "with open('MNA_NLP_semana_02_Actividad_datos.txt', 'r') as archivo:\n",
        "    # Lee todo el contenido del archivo y lo almacena en una cadena de texto\n",
        "    contenido = archivo.read()\n",
        "\n",
        "    # Busca todas las palabras que cumplan con los criterios y las almacena en la lista\n",
        "    palabras_encontradas = re.findall(r'\\bso[o]{2,}\\b|\\bg[o]{3,}d\\b', contenido, flags=re.IGNORECASE)\n",
        "\n",
        "# Imprime la lista de palabras encontradas\n",
        "print(\"Palabras encontradas:\")\n",
        "for palabra in palabras_encontradas:\n",
        "    print(palabra)\n",
        "\n",
        "# Imprime el número total de resultados encontrados\n",
        "print(f\"Se encontraron un total de {len(palabras_encontradas)} palabras que cumplen con los criterios.\")"
      ],
      "metadata": {
        "id": "A8Nf3B_cMlqg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8ef568a-712c-4ffc-aa79-b608835e4b07"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palabras encontradas:\n",
            "Sooooo\n",
            "soooo\n",
            "soooooo\n",
            "soooo\n",
            "Se encontraron un total de 4 palabras que cumplen con los criterios.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "svS4-vvPMl6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 9.**  \n",
        "\n",
        "Busca e imprime todas las palabras que tengan una longitud mayor estrictamente a 10 caracteres alfabéticos.\n",
        "\n",
        "No se consideran los signos de puntuación o caracteres especiales en la longitud de estas cadenas, solo caracteres alfabéticos en mayúsculas o minúsculas.\n",
        "\n",
        "Indica la cantidad de palabras encontradas.\n"
      ],
      "metadata": {
        "id": "hkak1opjMmlk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Inicializa una lista para almacenar las palabras que cumplen con los criterios\n",
        "palabras_encontradas = []\n",
        "\n",
        "# Abre el archivo en modo lectura ('r')\n",
        "with open('MNA_NLP_semana_02_Actividad_datos.txt', 'r') as archivo:\n",
        "    # Lee todo el contenido del archivo y lo almacena en una cadena de texto\n",
        "    contenido = archivo.read()\n",
        "\n",
        "    # Busca todas las palabras que cumplan con los criterios y las almacena en la lista\n",
        "    palabras_encontradas = re.findall(r'\\b[a-zA-Z]{11,}\\b', contenido)\n",
        "\n",
        "# Imprime la lista de palabras encontradas\n",
        "print(\"Palabras encontradas:\")\n",
        "for palabra in palabras_encontradas:\n",
        "    print(palabra)\n",
        "\n",
        "# Imprime la cantidad de palabras encontradas\n",
        "print(f\"Se encontraron un total de {len(palabras_encontradas)} palabras que cumplen con los criterios.\")"
      ],
      "metadata": {
        "id": "PYxdp3uhMoD0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35e0fc29-b13d-41ee-bff9-93311a041352"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palabras encontradas:\n",
            "recommendation\n",
            "recommended\n",
            "overwhelmed\n",
            "inexpensive\n",
            "establishment\n",
            "imaginative\n",
            "opportunity\n",
            "experiencing\n",
            "underwhelming\n",
            "relationship\n",
            "unsatisfying\n",
            "disappointing\n",
            "outrageously\n",
            "disappointing\n",
            "expectations\n",
            "restaurants\n",
            "suggestions\n",
            "disappointed\n",
            "considering\n",
            "Unfortunately\n",
            "immediately\n",
            "ingredients\n",
            "accommodations\n",
            "maintaining\n",
            "Interesting\n",
            "disrespected\n",
            "accordingly\n",
            "unbelievable\n",
            "cheeseburger\n",
            "descriptions\n",
            "inexpensive\n",
            "disappointed\n",
            "Veggitarian\n",
            "outstanding\n",
            "recommendation\n",
            "disappointed\n",
            "disappointed\n",
            "neighborhood\n",
            "disappointed\n",
            "corporation\n",
            "considering\n",
            "exceptional\n",
            "shawarrrrrrma\n",
            "disappointed\n",
            "vinaigrette\n",
            "immediately\n",
            "unbelievably\n",
            "replenished\n",
            "disappointed\n",
            "enthusiastic\n",
            "Outstanding\n",
            "comfortable\n",
            "interesting\n",
            "INCONSIDERATE\n",
            "considering\n",
            "transcendant\n",
            "disappointment\n",
            "disappointed\n",
            "disappointed\n",
            "overwhelmed\n",
            "professional\n",
            "Furthermore\n",
            "combination\n",
            "connoisseur\n",
            "profiterole\n",
            "outstanding\n",
            "acknowledged\n",
            "ventilation\n",
            "beautifully\n",
            "establishment\n",
            "extraordinary\n",
            "disappointed\n",
            "cheesecurds\n",
            "disappointed\n",
            "interesting\n",
            "experienced\n",
            "opportunity\n",
            "disgraceful\n",
            "restaurants\n",
            "ESTABLISHMENT\n",
            "recommended\n",
            "disappointed\n",
            "recommended\n",
            "acknowledged\n",
            "presentation\n",
            "Philadelphia\n",
            "disappointed\n",
            "disappointing\n",
            "grandmother\n",
            "drastically\n",
            "informative\n",
            "Disappointed\n",
            "constructed\n",
            "comfortable\n",
            "Smashburger\n",
            "cheeseburger\n",
            "neighborhood\n",
            "disappointed\n",
            "hospitality\n",
            "recommending\n",
            "disappointed\n",
            "deliciously\n",
            "compliments\n",
            "recommendation\n",
            "establishment\n",
            "calligraphy\n",
            "traditional\n",
            "combination\n",
            "Unfortunately\n",
            "Wienerschnitzel\n",
            "unfortunately\n",
            "considering\n",
            "highlighted\n",
            "Mediterranean\n",
            "unprofessional\n",
            "anticipated\n",
            "disappointing\n",
            "unexperienced\n",
            "disrespected\n",
            "professional\n",
            "restaurants\n",
            "Disappointing\n",
            "WAAAAAAyyyyyyyyyy\n",
            "reservation\n",
            "imagination\n",
            "undercooked\n",
            "disappointed\n",
            "disappointment\n",
            "disappointment\n",
            "deuchebaggery\n",
            "disappointed\n",
            "disappointment\n",
            "immediately\n",
            "Unfortunately\n",
            "disapppointment\n",
            "circumstances\n",
            "undercooked\n",
            "caterpillar\n",
            "presentation\n",
            "disappointed\n",
            "underwhelming\n",
            "Se encontraron un total de 141 palabras que cumplen con los criterios.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BR7e2F4FMof-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 10.**  \n",
        "\n",
        "Busca e imprime todas las palabras que inician con una letra mayúscula y terminan con una minúscula, pero que además no sea la primera palabra del comentario/string. \n",
        "\n",
        "Indica la cantidad de resultados obtenidos."
      ],
      "metadata": {
        "id": "ApjTNzSxMpDc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Inicializa una lista para almacenar las palabras que cumplen con los criterios\n",
        "palabras_encontradas = []\n",
        "\n",
        "# Abre el archivo en modo lectura ('r')\n",
        "with open('MNA_NLP_semana_02_Actividad_datos.txt', 'r') as archivo:\n",
        "    # Lee todo el contenido del archivo y lo almacena en una cadena de texto\n",
        "    contenido = archivo.read()\n",
        "\n",
        "    # Busca todas las palabras que cumplan con los criterios y las almacena en la lista\n",
        "    palabras_encontradas = re.findall(r'(?<!\\b\\w)[A-Z][a-zA-Z]*[a-z]\\b', contenido)\n",
        "\n",
        "# Imprime la lista de palabras encontradas\n",
        "print(\"Palabras encontradas:\")\n",
        "for palabra in palabras_encontradas:\n",
        "    print(palabra)\n",
        "\n",
        "# Imprime la cantidad de palabras encontradas\n",
        "print(f\"Se encontraron un total de {len(palabras_encontradas)} palabras que cumplen con los criterios.\")"
      ],
      "metadata": {
        "id": "Vb0ndRGAMqdL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40ad4db7-0c96-4ea9-b1a9-ff767443e02c"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palabras encontradas:\n",
            "Wow\n",
            "Loved\n",
            "Crust\n",
            "Not\n",
            "Stopped\n",
            "May\n",
            "Rick\n",
            "Steve\n",
            "The\n",
            "Now\n",
            "Honeslty\n",
            "The\n",
            "The\n",
            "Service\n",
            "Would\n",
            "The\n",
            "Cape\n",
            "Cod\n",
            "Highly\n",
            "Waitress\n",
            "This\n",
            "Vegas\n",
            "The\n",
            "Burrittos\n",
            "Blah\n",
            "The\n",
            "Service\n",
            "The\n",
            "So\n",
            "That\n",
            "They\n",
            "This\n",
            "Mexican\n",
            "Took\n",
            "Luke\n",
            "Our\n",
            "The\n",
            "Also\n",
            "This\n",
            "Overall\n",
            "The\n",
            "Ample\n",
            "Poor\n",
            "My\n",
            "Hiro\n",
            "Service\n",
            "The\n",
            "There\n",
            "Hard\n",
            "On\n",
            "Frozen\n",
            "The\n",
            "It\n",
            "The\n",
            "If\n",
            "Firehouse\n",
            "My\n",
            "Greek\n",
            "Greek\n",
            "We\n",
            "He\n",
            "Their\n",
            "They\n",
            "The\n",
            "Loved\n",
            "The\n",
            "Heart\n",
            "Attack\n",
            "Grill\n",
            "Vegas\n",
            "Not\n",
            "The\n",
            "The\n",
            "At\n",
            "This\n",
            "The\n",
            "We\n",
            "We\n",
            "Great\n",
            "Always\n",
            "Dos\n",
            "Gringos\n",
            "Update\n",
            "We\n",
            "The\n",
            "Jeff\n",
            "Really\n",
            "The\n",
            "It\n",
            "Excalibur\n",
            "The\n",
            "Very\n",
            "Bad\n",
            "Customer\n",
            "Service\n",
            "The\n",
            "Today\n",
            "There\n",
            "Vegas\n",
            "Rice\n",
            "Company\n",
            "Coming\n",
            "The\n",
            "This\n",
            "The\n",
            "Pho\n",
            "The\n",
            "All\n",
            "Omelets\n",
            "Everything\n",
            "In\n",
            "It\n",
            "Never\n",
            "Hard\n",
            "Rock\n",
            "Casino\n",
            "Best\n",
            "We\n",
            "Will\n",
            "Food\n",
            "It\n",
            "On\n",
            "Our\n",
            "The\n",
            "Best\n",
            "Buffet\n",
            "This\n",
            "So\n",
            "Tigerlilly\n",
            "The\n",
            "The\n",
            "Will\n",
            "Sooooo\n",
            "Yama\n",
            "At\n",
            "This\n",
            "Thai\n",
            "Nice\n",
            "Good\n",
            "Check\n",
            "It\n",
            "Kind\n",
            "Although\n",
            "Indian\n",
            "Worst\n",
            "Service\n",
            "The\n",
            "We\n",
            "Host\n",
            "Bland\n",
            "Not\n",
            "Phenomenal\n",
            "Definitely\n",
            "Vegas\n",
            "This\n",
            "Penne\n",
            "They\n",
            "The\n",
            "Delicious\n",
            "Lox\n",
            "Great\n",
            "Subway\n",
            "Subway\n",
            "This\n",
            "Vegas\n",
            "He\n",
            "Vegas\n",
            "My\n",
            "Don\n",
            "The\n",
            "My\n",
            "And\n",
            "Nice\n",
            "The\n",
            "The\n",
            "The\n",
            "We\n",
            "My\n",
            "This\n",
            "Mandalay\n",
            "Bay\n",
            "We\n",
            "Crostini\n",
            "Some\n",
            "Great\n",
            "Voodoo\n",
            "Unfortunately\n",
            "Their\n",
            "Avoid\n",
            "Restaurant\n",
            "This\n",
            "Phoenix\n",
            "So\n",
            "Bacon\n",
            "We\n",
            "This\n",
            "Vegas\n",
            "The\n",
            "Lordy\n",
            "Khao\n",
            "Soi\n",
            "Everything\n",
            "Perhaps\n",
            "The\n",
            "The\n",
            "Not\n",
            "We\n",
            "The\n",
            "It\n",
            "Love\n",
            "Lemon\n",
            "The\n",
            "Interesting\n",
            "What\n",
            "Also\n",
            "Both\n",
            "When\n",
            "Joey\n",
            "Valley\n",
            "Phoenix\n",
            "Magazine\n",
            "The\n",
            "Pho\n",
            "The\n",
            "Fridays\n",
            "Very\n",
            "It\n",
            "Food\n",
            "The\n",
            "Great\n",
            "Service\n",
            "Very\n",
            "The\n",
            "Must\n",
            "The\n",
            "If\n",
            "For\n",
            "My\n",
            "Won\n",
            "Extremely\n",
            "Tasty\n",
            "Waitress\n",
            "Soggy\n",
            "The\n",
            "Jamaican\n",
            "Which\n",
            "The\n",
            "The\n",
            "Lobster\n",
            "Bisque\n",
            "Bussell\n",
            "Sprouts\n",
            "Risotto\n",
            "Filet\n",
            "Hopefully\n",
            "It\n",
            "This\n",
            "The\n",
            "Otto\n",
            "As\n",
            "This\n",
            "This\n",
            "If\n",
            "Very\n",
            "Ordered\n",
            "Yeah\n",
            "Great\n",
            "If\n",
            "The\n",
            "Honestly\n",
            "If\n",
            "Not\n",
            "Everyone\n",
            "Horrible\n",
            "Now\n",
            "By\n",
            "It\n",
            "Also\n",
            "Drinks\n",
            "Seriously\n",
            "Much\n",
            "Vegas\n",
            "The\n",
            "Based\n",
            "Owner\n",
            "There\n",
            "The\n",
            "Greek\n",
            "Overall\n",
            "Now\n",
            "We\n",
            "Fantastic\n",
            "They\n",
            "Vegas\n",
            "The\n",
            "Good\n",
            "The\n",
            "Plus\n",
            "The\n",
            "Thus\n",
            "Just\n",
            "For\n",
            "The\n",
            "Veggitarian\n",
            "You\n",
            "You\n",
            "Stopped\n",
            "Madison\n",
            "Ironman\n",
            "The\n",
            "Jenni\n",
            "Pho\n",
            "The\n",
            "Bachi\n",
            "Burger\n",
            "Service\n",
            "This\n",
            "Great\n",
            "Pizza\n",
            "Salads\n",
            "Things\n",
            "They\n",
            "We\n",
            "This\n",
            "Yelpers\n",
            "Waited\n",
            "Just\n",
            "The\n",
            "You\n",
            "Before\n",
            "Bachi\n",
            "Never\n",
            "The\n",
            "Good\n",
            "Please\n",
            "The\n",
            "Food\n",
            "Good\n",
            "Service\n",
            "This\n",
            "Will\n",
            "As\n",
            "In\n",
            "Fantastic\n",
            "She\n",
            "English\n",
            "The\n",
            "Never\n",
            "Great\n",
            "The\n",
            "By\n",
            "Back\n",
            "And\n",
            "All\n",
            "The\n",
            "Also\n",
            "Service\n",
            "Favorite\n",
            "The\n",
            "You\n",
            "They\n",
            "When\n",
            "The\n",
            "Pizza\n",
            "Hut\n",
            "Both\n",
            "We\n",
            "Everything\n",
            "Great\n",
            "First\n",
            "Seat\n",
            "The\n",
            "Gold\n",
            "Standard\n",
            "There\n",
            "Of\n",
            "The\n",
            "Thai\n",
            "It\n",
            "Tucson\n",
            "The\n",
            "Vegas\n",
            "Pretty\n",
            "This\n",
            "Chipotle\n",
            "Classy\n",
            "Baseball\n",
            "We\n",
            "He\n",
            "Everyone\n",
            "It\n",
            "It\n",
            "On\n",
            "Sadly\n",
            "Gordon\n",
            "Ramsey\n",
            "Steak\n",
            "Vegas\n",
            "As\n",
            "Best\n",
            "The\n",
            "The\n",
            "This\n",
            "Outstanding\n",
            "Best\n",
            "Food\n",
            "Pretty\n",
            "Definitely\n",
            "Server\n",
            "My\n",
            "Lobster\n",
            "Bisque\n",
            "Would\n",
            "Vegas\n",
            "The\n",
            "He\n",
            "They\n",
            "The\n",
            "They\n",
            "Eggplant\n",
            "Green\n",
            "Bean\n",
            "And\n",
            "Best\n",
            "In\n",
            "The\n",
            "They\n",
            "The\n",
            "Halibut\n",
            "The\n",
            "Vegas\n",
            "This\n",
            "This\n",
            "Def\n",
            "If\n",
            "We\n",
            "Vegas\n",
            "Service\n",
            "Vegas\n",
            "Crystals\n",
            "Aria\n",
            "To\n",
            "Ians\n",
            "Kids\n",
            "Service\n",
            "Cooked\n",
            "This\n",
            "Overall\n",
            "Bouchon\n",
            "Great\n",
            "San\n",
            "Francisco\n",
            "Bay\n",
            "Area\n",
            "Today\n",
            "Buldogis\n",
            "Gourmet\n",
            "Hot\n",
            "Dog\n",
            "Left\n",
            "Food\n",
            "Service\n",
            "Come\n",
            "For\n",
            "Gave\n",
            "But\n",
            "First\n",
            "Our\n",
            "From\n",
            "On\n",
            "Furthermore\n",
            "We\n",
            "What\n",
            "No\n",
            "This\n",
            "Waiter\n",
            "Strike\n",
            "These\n",
            "We\n",
            "Service\n",
            "Ordered\n",
            "So\n",
            "It\n",
            "Steiners\n",
            "Wow\n",
            "If\n",
            "Anyway\n",
            "Nothing\n",
            "Each\n",
            "Not\n",
            "Will\n",
            "Sauce\n",
            "The\n",
            "My\n",
            "Food\n",
            "The\n",
            "The\n",
            "The\n",
            "Nargile\n",
            "Best\n",
            "We\n",
            "Definitely\n",
            "The\n",
            "Im\n",
            "The\n",
            "The\n",
            "The\n",
            "Carly\n",
            "This\n",
            "Love\n",
            "This\n",
            "Vegas\n",
            "Very\n",
            "The\n",
            "Great\n",
            "Don\n",
            "Total\n",
            "Camelback\n",
            "Flower\n",
            "Shop\n",
            "Cartel\n",
            "Coffee\n",
            "Third\n",
            "We\n",
            "The\n",
            "We\n",
            "We\n",
            "This\n",
            "Las\n",
            "Vegas\n",
            "Seafood\n",
            "The\n",
            "Delicious\n",
            "This\n",
            "They\n",
            "It\n",
            "How\n",
            "The\n",
            "Worse\n",
            "Bunch\n",
            "Very\n",
            "Their\n",
            "And\n",
            "The\n",
            "This\n",
            "Their\n",
            "Waitress\n",
            "Mom\n",
            "Cant\n",
            "The\n",
            "The\n",
            "Overall\n",
            "Noca\n",
            "My\n",
            "Terrible\n",
            "Thoroughly\n",
            "Give\n",
            "By\n",
            "Reasonably\n",
            "Everything\n",
            "The\n",
            "At\n",
            "Anyway\n",
            "Point\n",
            "Oh\n",
            "If\n",
            "Those\n",
            "Similarly\n",
            "And\n",
            "Be\n",
            "This\n",
            "The\n",
            "Everything\n",
            "This\n",
            "The\n",
            "Vegas\n",
            "Sat\n",
            "Sun\n",
            "If\n",
            "Mexican\n",
            "Terrible\n",
            "An\n",
            "Frenchman\n",
            "If\n",
            "Great\n",
            "Worst\n",
            "The\n",
            "We\n",
            "The\n",
            "No\n",
            "Just\n",
            "Perfect\n",
            "Last\n",
            "The\n",
            "My\n",
            "Vegas\n",
            "Nice\n",
            "However\n",
            "All\n",
            "My\n",
            "Palm\n",
            "After\n",
            "Generous\n",
            "The\n",
            "Are\n",
            "Food\n",
            "Eew\n",
            "This\n",
            "We\n",
            "Waited\n",
            "He\n",
            "Our\n",
            "The\n",
            "Service\n",
            "The\n",
            "As\n",
            "Boy\n",
            "Over\n",
            "If\n",
            "Thai\n",
            "Their\n",
            "After\n",
            "Great\n",
            "All\n",
            "My\n",
            "Toast\n",
            "The\n",
            "Great\n",
            "The\n",
            "Thai\n",
            "It\n",
            "It\n",
            "The\n",
            "It\n",
            "Phoenix\n",
            "Crema\n",
            "Not\n",
            "Philadelphia\n",
            "We\n",
            "They\n",
            "Good\n",
            "Couldn\n",
            "The\n",
            "It\n",
            "We\n",
            "North\n",
            "Scottsdale\n",
            "The\n",
            "Sorry\n",
            "An\n",
            "The\n",
            "My\n",
            "Bloody\n",
            "Mary\n",
            "Despite\n",
            "They\n",
            "Pho\n",
            "Very\n",
            "The\n",
            "Pretty\n",
            "Ambience\n",
            "Best\n",
            "Any\n",
            "The\n",
            "Four\n",
            "The\n",
            "Same\n",
            "High\n",
            "Caesar\n",
            "Ordered\n",
            "We\n",
            "Tried\n",
            "After\n",
            "This\n",
            "The\n",
            "Macarons\n",
            "Our\n",
            "Maybe\n",
            "This\n",
            "Very\n",
            "Experience\n",
            "What\n",
            "Food\n",
            "Great\n",
            "We\n",
            "Very\n",
            "Very\n",
            "Disappointed\n",
            "Big\n",
            "Bay\n",
            "Plater\n",
            "Great\n",
            "It\n",
            "Not\n",
            "The\n",
            "The\n",
            "Hands\n",
            "Italian\n",
            "That\n",
            "Vegas\n",
            "It\n",
            "The\n",
            "Baba\n",
            "Ganoush\n",
            "Very\n",
            "The\n",
            "Both\n",
            "Eclectic\n",
            "The\n",
            "The\n",
            "And\n",
            "The\n",
            "Nobu\n",
            "Google\n",
            "Smashburger\n",
            "As\n",
            "What\n",
            "Awesome\n",
            "The\n",
            "It\n",
            "Service\n",
            "Your\n",
            "Dessert\n",
            "Panna\n",
            "Cotta\n",
            "Very\n",
            "Damn\n",
            "Total\n",
            "Prices\n",
            "The\n",
            "The\n",
            "Good\n",
            "It\n",
            "The\n",
            "Hawaiian\n",
            "Breeze\n",
            "Mango\n",
            "Magic\n",
            "Pineapple\n",
            "Delight\n",
            "Went\n",
            "We\n",
            "Needless\n",
            "Anyways\n",
            "The\n",
            "The\n",
            "Strip\n",
            "Steak\n",
            "Have\n",
            "Our\n",
            "The\n",
            "Paradise\n",
            "Valley\n",
            "Cibo\n",
            "The\n",
            "Would\n",
            "Service\n",
            "That\n",
            "Not\n",
            "Thumbs\n",
            "Up\n",
            "If\n",
            "Italian\n",
            "Only\n",
            "Pros\n",
            "Large\n",
            "Nice\n",
            "Great\n",
            "The\n",
            "They\n",
            "Tonight\n",
            "Elk\n",
            "Filet\n",
            "After\n",
            "We\n",
            "Cute\n",
            "The\n",
            "The\n",
            "Special\n",
            "Dylan\n",
            "All\n",
            "Awesome\n",
            "Great\n",
            "One\n",
            "The\n",
            "Han\n",
            "Nan\n",
            "Chicken\n",
            "As\n",
            "The\n",
            "Ryan\n",
            "Bar\n",
            "Edinburgh\n",
            "Nicest\n",
            "Chinese\n",
            "Overall\n",
            "They\n",
            "Indian\n",
            "Probably\n",
            "Friend\n",
            "Try\n",
            "Chinese\n",
            "Never\n",
            "The\n",
            "It\n",
            "When\n",
            "Will\n",
            "There\n",
            "An\n",
            "Wonderful\n",
            "The\n",
            "Level\n",
            "We\n",
            "Main\n",
            "When\n",
            "This\n",
            "The\n",
            "The\n",
            "Food\n",
            "Prices\n",
            "The\n",
            "The\n",
            "But\n",
            "Tasted\n",
            "One\n",
            "Phoenix\n",
            "The\n",
            "It\n",
            "Both\n",
            "Hot\n",
            "Sour\n",
            "Egg\n",
            "Flower\n",
            "Soups\n",
            "Stars\n",
            "My\n",
            "Great\n",
            "Sunday\n",
            "Hunan\n",
            "What\n",
            "The\n",
            "Their\n",
            "These\n",
            "So\n",
            "The\n",
            "My\n",
            "Unfortunately\n",
            "Join\n",
            "Perfect\n",
            "Bland\n",
            "The\n",
            "The\n",
            "We\n",
            "The\n",
            "Great\n",
            "When\n",
            "Pita\n",
            "Once\n",
            "Paying\n",
            "Wienerschnitzel\n",
            "The\n",
            "Maine\n",
            "Lobster\n",
            "Roll\n",
            "My\n",
            "So\n",
            "The\n",
            "This\n",
            "Mediocre\n",
            "Once\n",
            "And\n",
            "Why\n",
            "This\n",
            "They\n",
            "Not\n",
            "Lastly\n",
            "The\n",
            "The\n",
            "The\n",
            "This\n",
            "It\n",
            "The\n",
            "The\n",
            "It\n",
            "This\n",
            "But\n",
            "Do\n",
            "The\n",
            "Awful\n",
            "Won\n",
            "Food\n",
            "For\n",
            "The\n",
            "Kabuki\n",
            "Do\n",
            "Very\n",
            "No\n",
            "Best\n",
            "Maria\n",
            "They\n",
            "Just\n",
            "Food\n",
            "Caballero\n",
            "The\n",
            "We\n",
            "This\n",
            "In\n",
            "To\n",
            "Bad\n",
            "So\n",
            "The\n",
            "The\n",
            "Wife\n",
            "My\n",
            "Went\n",
            "Some\n",
            "Worst\n",
            "This\n",
            "Talk\n",
            "Hot\n",
            "Everything\n",
            "Always\n",
            "They\n",
            "This\n",
            "For\n",
            "Strip\n",
            "The\n",
            "The\n",
            "Costco\n",
            "All\n",
            "My\n",
            "Weird\n",
            "There\n",
            "Go\n",
            "To\n",
            "Place\n",
            "Gyros\n",
            "Japanese\n",
            "Now\n",
            "The\n",
            "We\n",
            "Albondigas\n",
            "On\n",
            "The\n",
            "After\n",
            "Seriously\n",
            "No\n",
            "My\n",
            "Mediterranean\n",
            "Chicken\n",
            "Salad\n",
            "Their\n",
            "Pricing\n",
            "Mellow\n",
            "Mushroom\n",
            "Worst\n",
            "Thai\n",
            "If\n",
            "Vegas\n",
            "The\n",
            "Highly\n",
            "Overall\n",
            "Spend\n",
            "Their\n",
            "Mmmm\n",
            "The\n",
            "Buffet\n",
            "Bellagio\n",
            "And\n",
            "My\n",
            "Also\n",
            "After\n",
            "The\n",
            "We\n",
            "This\n",
            "Vegas\n",
            "Very\n",
            "How\n",
            "The\n",
            "There\n",
            "They\n",
            "What\n",
            "Christmas\n",
            "Eve\n",
            "Needless\n",
            "This\n",
            "Every\n",
            "The\n",
            "However\n",
            "It\n",
            "It\n",
            "We\n",
            "Disappointing\n",
            "The\n",
            "Denny\n",
            "If\n",
            "WAAAAAAyyyyyyyyyy\n",
            "We\n",
            "The\n",
            "This\n",
            "The\n",
            "Don\n",
            "The\n",
            "The\n",
            "It\n",
            "Probably\n",
            "Not\n",
            "The\n",
            "The\n",
            "It\n",
            "This\n",
            "Maybe\n",
            "Vegetarian\n",
            "It\n",
            "The\n",
            "The\n",
            "Con\n",
            "The\n",
            "But\n",
            "Then\n",
            "The\n",
            "My\n",
            "The\n",
            "Insults\n",
            "If\n",
            "She\n",
            "After\n",
            "Del\n",
            "Taco\n",
            "It\n",
            "But\n",
            "Hell\n",
            "We\n",
            "The\n",
            "Unfortunately\n",
            "The\n",
            "Your\n",
            "Heimer\n",
            "What\n",
            "Overpriced\n",
            "We\n",
            "Food\n",
            "It\n",
            "All\n",
            "Ha\n",
            "Long\n",
            "Bay\n",
            "The\n",
            "Subway\n",
            "Shrimp\n",
            "When\n",
            "Brushfire\n",
            "It\n",
            "It\n",
            "Mirage\n",
            "The\n",
            "Spend\n",
            "In\n",
            "Appetite\n",
            "Overall\n",
            "The\n",
            "Ninja\n",
            "Sushi\n",
            "Then\n",
            "Se encontraron un total de 1064 palabras que cumplen con los criterios.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dLPTRPnTMqqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 11.**  \n",
        "\n",
        "Busca e imprime la secuencia de dos o más palabras que están separadas por un guion, \"-\", sin que tengan espacios en blanco entre ellas.\n",
        "\n",
        "Por ejemplo \"Go-Kart\" sería válido, pero \"Go  -Kart\" o \"Go  -  Kart\" no lo serían. \n",
        "\n",
        "Indica la cantidad de resultados obtenidos."
      ],
      "metadata": {
        "id": "u7nfm4KhMrNW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Inicializa una lista para almacenar las secuencias encontradas\n",
        "secuencias_encontradas = []\n",
        "\n",
        "# Abre el archivo en modo lectura ('r')\n",
        "with open('MNA_NLP_semana_02_Actividad_datos.txt', 'r') as archivo:\n",
        "    # Lee todo el contenido del archivo y lo almacena en una cadena de texto\n",
        "    contenido = archivo.read()\n",
        "\n",
        "    # Busca todas las secuencias que cumplan con los criterios y las almacena en la lista\n",
        "    secuencias_encontradas = re.findall(r'\\b\\w+-\\w+\\b', contenido)\n",
        "\n",
        "# Imprime la lista de secuencias encontradas\n",
        "print(\"Secuencias encontradas:\")\n",
        "for secuencia in secuencias_encontradas:\n",
        "    print(secuencia)\n",
        "\n",
        "# Imprime la cantidad de secuencias encontradas\n",
        "print(f\"Se encontraron un total de {len(secuencias_encontradas)} secuencias que cumplen con los criterios.\")"
      ],
      "metadata": {
        "id": "OwU-a7eGMsub",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b5c450b-3aea-41f6-ac22-c8e91fcc0390"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Secuencias encontradas:\n",
            "flat-lined\n",
            "hands-down\n",
            "must-stop\n",
            "sub-par\n",
            "Service-check\n",
            "in-house\n",
            "been-stepped\n",
            "in-and\n",
            "tracked-everywhere\n",
            "multi-grain\n",
            "to-go\n",
            "non-customer\n",
            "High-quality\n",
            "sit-down\n",
            "over-whelm\n",
            "low-key\n",
            "non-fancy\n",
            "golden-crispy\n",
            "over-priced\n",
            "over-hip\n",
            "under-services\n",
            "Se encontraron un total de 21 secuencias que cumplen con los criterios.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SgzIL74ZMtGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 12.**  \n",
        "\n",
        "Busca e imprime todas las palabras que terminan en \"ing\" o \"ed\". \n",
        "\n",
        "Indica la cantidad de palabras que encontraste de cada una."
      ],
      "metadata": {
        "id": "DEIgl79HMthr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Inicializa contadores para las palabras encontradas\n",
        "contador_ing = 0\n",
        "contador_ed = 0\n",
        "\n",
        "# Abre el archivo en modo lectura ('r')\n",
        "with open('MNA_NLP_semana_02_Actividad_datos.txt', 'r') as archivo:\n",
        "    # Lee todo el contenido del archivo y lo almacena en una cadena de texto\n",
        "    contenido = archivo.read()\n",
        "\n",
        "    # Busca todas las palabras que terminen en \"ing\" o \"ed\"\n",
        "    palabras_ing = re.findall(r'\\b\\w+ing\\b', contenido)\n",
        "    palabras_ed = re.findall(r'\\b\\w+ed\\b', contenido)\n",
        "\n",
        "    # Cuenta la cantidad de palabras encontradas para cada una\n",
        "    contador_ing = len(palabras_ing)\n",
        "    contador_ed = len(palabras_ed)\n",
        "\n",
        "# Imprime las palabras encontradas\n",
        "print(\"Palabras que terminan en 'ing':\")\n",
        "for palabra in palabras_ing:\n",
        "    print(palabra)\n",
        "\n",
        "print(\"Palabras que terminan en 'ed':\")\n",
        "for palabra in palabras_ed:\n",
        "    print(palabra)\n",
        "\n",
        "# Imprime la cantidad de palabras encontradas para cada una\n",
        "print(f\"Se encontraron {contador_ing} palabras que terminan en 'ing'.\")\n",
        "print(f\"Se encontraron {contador_ed} palabras que terminan en 'ed'.\")"
      ],
      "metadata": {
        "id": "I4TSofBMMv9y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b379faa-8069-4577-fa96-9ba608a4ef6a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palabras que terminan en 'ing':\n",
            "during\n",
            "getting\n",
            "being\n",
            "being\n",
            "amazing\n",
            "running\n",
            "redeeming\n",
            "getting\n",
            "thing\n",
            "dressing\n",
            "refreshing\n",
            "running\n",
            "amazing\n",
            "nothing\n",
            "appalling\n",
            "wasting\n",
            "eating\n",
            "going\n",
            "Coming\n",
            "experiencing\n",
            "underwhelming\n",
            "eating\n",
            "raving\n",
            "spring\n",
            "unsatisfying\n",
            "amazing\n",
            "Everything\n",
            "disappointing\n",
            "dining\n",
            "flirting\n",
            "thing\n",
            "coming\n",
            "playing\n",
            "ordering\n",
            "arriving\n",
            "disappointing\n",
            "preparing\n",
            "loving\n",
            "liking\n",
            "reviewing\n",
            "venturing\n",
            "including\n",
            "during\n",
            "changing\n",
            "going\n",
            "considering\n",
            "coming\n",
            "going\n",
            "everything\n",
            "looking\n",
            "dressing\n",
            "dining\n",
            "Everything\n",
            "amazing\n",
            "judging\n",
            "maintaining\n",
            "asking\n",
            "having\n",
            "something\n",
            "lacking\n",
            "Interesting\n",
            "preparing\n",
            "missing\n",
            "feeling\n",
            "exceeding\n",
            "inviting\n",
            "climbing\n",
            "waiting\n",
            "coming\n",
            "being\n",
            "lacking\n",
            "going\n",
            "amazing\n",
            "dealing\n",
            "annoying\n",
            "falling\n",
            "sporting\n",
            "amazing\n",
            "providing\n",
            "building\n",
            "lighting\n",
            "going\n",
            "nothing\n",
            "working\n",
            "eating\n",
            "dressing\n",
            "being\n",
            "outstanding\n",
            "getting\n",
            "amazing\n",
            "rating\n",
            "eating\n",
            "writing\n",
            "everything\n",
            "dining\n",
            "boring\n",
            "charming\n",
            "going\n",
            "making\n",
            "pricing\n",
            "considering\n",
            "amazing\n",
            "Everything\n",
            "nothing\n",
            "nothing\n",
            "driving\n",
            "during\n",
            "evening\n",
            "Outstanding\n",
            "buying\n",
            "handling\n",
            "wasting\n",
            "craving\n",
            "dining\n",
            "interesting\n",
            "amazing\n",
            "being\n",
            "outshining\n",
            "starving\n",
            "coming\n",
            "considering\n",
            "shopping\n",
            "nothing\n",
            "getting\n",
            "trying\n",
            "eating\n",
            "going\n",
            "everything\n",
            "Nothing\n",
            "going\n",
            "outstanding\n",
            "running\n",
            "forgetting\n",
            "upgrading\n",
            "eating\n",
            "bring\n",
            "hoping\n",
            "living\n",
            "dining\n",
            "filling\n",
            "amazing\n",
            "Everything\n",
            "thing\n",
            "amazing\n",
            "Everything\n",
            "interesting\n",
            "amazing\n",
            "amazing\n",
            "waiting\n",
            "going\n",
            "going\n",
            "dining\n",
            "saving\n",
            "something\n",
            "trying\n",
            "disgusting\n",
            "hankering\n",
            "being\n",
            "being\n",
            "being\n",
            "setting\n",
            "sitting\n",
            "waiting\n",
            "satisfying\n",
            "eating\n",
            "being\n",
            "freaking\n",
            "getting\n",
            "amazing\n",
            "disappointing\n",
            "seasoning\n",
            "going\n",
            "being\n",
            "bring\n",
            "letting\n",
            "evening\n",
            "waiting\n",
            "being\n",
            "eating\n",
            "going\n",
            "seating\n",
            "playing\n",
            "amazing\n",
            "staying\n",
            "giving\n",
            "talking\n",
            "amazing\n",
            "amazing\n",
            "amazing\n",
            "amazing\n",
            "filling\n",
            "dripping\n",
            "going\n",
            "serving\n",
            "recommending\n",
            "thing\n",
            "reading\n",
            "seating\n",
            "going\n",
            "everything\n",
            "thing\n",
            "sitting\n",
            "waiting\n",
            "bring\n",
            "revisiting\n",
            "coming\n",
            "anything\n",
            "feeling\n",
            "during\n",
            "thing\n",
            "being\n",
            "amazing\n",
            "being\n",
            "amazing\n",
            "satifying\n",
            "describing\n",
            "coming\n",
            "everything\n",
            "Paying\n",
            "going\n",
            "thing\n",
            "amazing\n",
            "getting\n",
            "cramming\n",
            "considering\n",
            "fucking\n",
            "going\n",
            "appealing\n",
            "getting\n",
            "coming\n",
            "Everything\n",
            "dealing\n",
            "everything\n",
            "something\n",
            "during\n",
            "dining\n",
            "cooking\n",
            "dining\n",
            "editing\n",
            "setting\n",
            "amazing\n",
            "rotating\n",
            "Pricing\n",
            "satisfying\n",
            "disappointing\n",
            "amazing\n",
            "returning\n",
            "running\n",
            "being\n",
            "thing\n",
            "nothing\n",
            "poisoning\n",
            "thinking\n",
            "something\n",
            "going\n",
            "disgusting\n",
            "caring\n",
            "bring\n",
            "Disappointing\n",
            "saying\n",
            "going\n",
            "coming\n",
            "building\n",
            "seating\n",
            "dipping\n",
            "setting\n",
            "anything\n",
            "drinking\n",
            "serving\n",
            "doing\n",
            "putting\n",
            "getting\n",
            "looking\n",
            "coming\n",
            "staying\n",
            "lacking\n",
            "underwhelming\n",
            "drawing\n",
            "bring\n",
            "Palabras que terminan en 'ed':\n",
            "Loved\n",
            "Stopped\n",
            "loved\n",
            "ended\n",
            "overpriced\n",
            "tried\n",
            "disgusted\n",
            "shocked\n",
            "recommended\n",
            "performed\n",
            "red\n",
            "asked\n",
            "overwhelmed\n",
            "grossed\n",
            "melted\n",
            "provided\n",
            "cooked\n",
            "ordered\n",
            "realized\n",
            "Loved\n",
            "lined\n",
            "cooked\n",
            "ripped\n",
            "ripped\n",
            "petrified\n",
            "included\n",
            "expected\n",
            "seasoned\n",
            "cheated\n",
            "walked\n",
            "smelled\n",
            "tailored\n",
            "arrived\n",
            "roasted\n",
            "added\n",
            "cooked\n",
            "passed\n",
            "liked\n",
            "managed\n",
            "served\n",
            "overpriced\n",
            "checked\n",
            "disappointed\n",
            "red\n",
            "decorated\n",
            "served\n",
            "watched\n",
            "greeted\n",
            "seated\n",
            "waited\n",
            "flavored\n",
            "ordered\n",
            "ordered\n",
            "relocated\n",
            "impressed\n",
            "seated\n",
            "priced\n",
            "treated\n",
            "ordered\n",
            "used\n",
            "handed\n",
            "listed\n",
            "missed\n",
            "thrilled\n",
            "inspired\n",
            "desired\n",
            "overcooked\n",
            "decided\n",
            "looked\n",
            "dressed\n",
            "treated\n",
            "ordered\n",
            "sucked\n",
            "expected\n",
            "sucked\n",
            "imagined\n",
            "served\n",
            "arrived\n",
            "satisfied\n",
            "voted\n",
            "insulted\n",
            "disrespected\n",
            "dreamed\n",
            "lived\n",
            "stepped\n",
            "mixed\n",
            "showed\n",
            "realized\n",
            "loved\n",
            "needed\n",
            "loved\n",
            "wrapped\n",
            "uninspired\n",
            "Ordered\n",
            "uploaded\n",
            "covered\n",
            "supposed\n",
            "rolled\n",
            "stayed\n",
            "Based\n",
            "received\n",
            "privileged\n",
            "charged\n",
            "visited\n",
            "proclaimed\n",
            "disappointed\n",
            "Stopped\n",
            "dedicated\n",
            "liked\n",
            "disappointed\n",
            "waited\n",
            "waited\n",
            "burned\n",
            "waited\n",
            "disappointed\n",
            "Waited\n",
            "disappointed\n",
            "pulled\n",
            "prepared\n",
            "fried\n",
            "passed\n",
            "ordered\n",
            "toasted\n",
            "untoasted\n",
            "figured\n",
            "returned\n",
            "eyed\n",
            "disappointed\n",
            "pleased\n",
            "replenished\n",
            "disappointed\n",
            "treated\n",
            "offered\n",
            "tasted\n",
            "dropped\n",
            "decorated\n",
            "served\n",
            "walked\n",
            "stuffed\n",
            "located\n",
            "Cooked\n",
            "disappointed\n",
            "screwed\n",
            "frustrated\n",
            "iced\n",
            "stuffed\n",
            "disappointed\n",
            "grossed\n",
            "enjoyed\n",
            "looked\n",
            "overwhelmed\n",
            "stayed\n",
            "smeared\n",
            "stepped\n",
            "tracked\n",
            "tried\n",
            "rushed\n",
            "loved\n",
            "Ordered\n",
            "cooked\n",
            "insulted\n",
            "contained\n",
            "enjoyed\n",
            "relaxed\n",
            "loved\n",
            "acknowledged\n",
            "trimmed\n",
            "cooked\n",
            "claimed\n",
            "handled\n",
            "asked\n",
            "limited\n",
            "boiled\n",
            "liked\n",
            "sliced\n",
            "attached\n",
            "humiliated\n",
            "fried\n",
            "impressed\n",
            "disappointed\n",
            "priced\n",
            "disappointed\n",
            "need\n",
            "need\n",
            "experienced\n",
            "waited\n",
            "seated\n",
            "decided\n",
            "pleased\n",
            "recommended\n",
            "helped\n",
            "witnessed\n",
            "Waited\n",
            "waited\n",
            "waited\n",
            "checked\n",
            "tasted\n",
            "disappointed\n",
            "served\n",
            "rated\n",
            "recommended\n",
            "pulled\n",
            "waited\n",
            "acknowledged\n",
            "perpared\n",
            "dusted\n",
            "powdered\n",
            "enjoyed\n",
            "expanded\n",
            "ended\n",
            "arrived\n",
            "wanted\n",
            "disappointed\n",
            "need\n",
            "checked\n",
            "impressed\n",
            "reheated\n",
            "tasted\n",
            "grilled\n",
            "focused\n",
            "roasted\n",
            "asked\n",
            "ignored\n",
            "tasted\n",
            "Ordered\n",
            "greeted\n",
            "seated\n",
            "Tried\n",
            "seated\n",
            "Disappointed\n",
            "ordered\n",
            "constructed\n",
            "fried\n",
            "requested\n",
            "used\n",
            "tasted\n",
            "drenched\n",
            "tried\n",
            "walked\n",
            "expected\n",
            "disappointed\n",
            "mortified\n",
            "impressed\n",
            "refrained\n",
            "pleased\n",
            "loved\n",
            "grilled\n",
            "reminded\n",
            "sucked\n",
            "hooked\n",
            "ordered\n",
            "disappointed\n",
            "seasoned\n",
            "added\n",
            "touched\n",
            "fried\n",
            "opened\n",
            "impressed\n",
            "watched\n",
            "Tasted\n",
            "ordered\n",
            "received\n",
            "impressed\n",
            "overcooked\n",
            "cooked\n",
            "needed\n",
            "served\n",
            "ordered\n",
            "overpriced\n",
            "packed\n",
            "opposed\n",
            "priced\n",
            "surprised\n",
            "focused\n",
            "overpriced\n",
            "tried\n",
            "enjoyed\n",
            "qualified\n",
            "tasted\n",
            "hated\n",
            "watched\n",
            "fried\n",
            "tried\n",
            "helped\n",
            "started\n",
            "highlighted\n",
            "used\n",
            "enjoyed\n",
            "ordered\n",
            "tasted\n",
            "asked\n",
            "refused\n",
            "tried\n",
            "toasted\n",
            "anticipated\n",
            "unexperienced\n",
            "insulted\n",
            "disrespected\n",
            "impressed\n",
            "puréed\n",
            "asked\n",
            "rated\n",
            "lacked\n",
            "sliced\n",
            "pulled\n",
            "undercooked\n",
            "seemed\n",
            "watered\n",
            "lacked\n",
            "disappointed\n",
            "overpriced\n",
            "ensued\n",
            "disappointed\n",
            "placed\n",
            "avoided\n",
            "received\n",
            "wanted\n",
            "sucked\n",
            "happened\n",
            "owned\n",
            "wanted\n",
            "Overpriced\n",
            "vomited\n",
            "started\n",
            "unwrapped\n",
            "lacked\n",
            "seemed\n",
            "undercooked\n",
            "closed\n",
            "refried\n",
            "dried\n",
            "disappointed\n",
            "impressed\n",
            "wasted\n",
            "poured\n",
            "Se encontraron 279 palabras que terminan en 'ing'.\n",
            "Se encontraron 335 palabras que terminan en 'ed'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AhGq6De2Mvyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Parte 3. Proceso de limpieza.**"
      ],
      "metadata": {
        "id": "70StdqAZa9E9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 13.**  \n",
        "\n",
        "Ahora realiza un proceso de limpieza del corpus que incluya los siguientes procesos:\n",
        "\n",
        "*   Solo se deben considerar caracteres alfabéticos. Es decir, se eliminan todos los signos de puntuación y caracteres especiales.\n",
        "*   Todos los caracteres alfabéticos se transforman a minúsculas.\n",
        "*   Se deben eliminar todos los espacios en blanco adicionales que se puedan encontrar en cada comentario.\n",
        "\n",
        "Al finalizar dicho proceso de limpieza, imprime el resultado de los primeros 10 comentarios resultantes. \n",
        "   \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xaDUFXHrMvX2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Leer archivo\n",
        "with open('MNA_NLP_semana_02_Actividad_datos.txt', 'r') as f:\n",
        "    corpus = f.readlines()\n",
        "\n",
        "# Proceso de limpieza\n",
        "clean_corpus = []\n",
        "for comentario in corpus:\n",
        "    # Solo caracteres alfabéticos\n",
        "    comentario = re.sub(r'[^a-zA-Z\\s]', '', comentario)\n",
        "    # Transformar a minúsculas\n",
        "    comentario = comentario.lower()\n",
        "    # Eliminar espacios en blanco adicionales\n",
        "    comentario = ' '.join(comentario.split())\n",
        "    clean_corpus.append(comentario)\n",
        "\n",
        "# Imprimir los primeros 10 comentarios limpios\n",
        "print(\"Primeros 10 comentarios limpios:\")\n",
        "for comentario in clean_corpus[:10]:\n",
        "    print(comentario)\n",
        "\n",
        "# Escribir resultados en un archivo de texto\n",
        "with open('corpus_limpio.txt', 'w') as f:\n",
        "    for comentario in clean_corpus:\n",
        "        f.write(comentario + '\\n')"
      ],
      "metadata": {
        "id": "K3kQzPOPMx0w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "680baef6-fb36-4c14-bd86-c6d671414677"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Primeros 10 comentarios limpios:\n",
            "wow loved this place\n",
            "crust is not good\n",
            "not tasty and the texture was just nasty\n",
            "stopped by during the late may bank holiday off rick steve recommendation and loved it\n",
            "the selection on the menu was great and so were the prices\n",
            "now i am getting angry and i want my damn pho\n",
            "honeslty it didnt taste that fresh\n",
            "the potatoes were like rubber and you could tell they had been made up ahead of time being kept under a warmer\n",
            "the fries were great too\n",
            "a great touch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mYEDlHSFMyJN"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 14.**  \n",
        "\n",
        "Con el resultado de la limpieza obtenido en la pregunta anterior, realiza ahora un proceso de tokenización por palabras del corpus. \n",
        "\n",
        "Es decir, al final de este proceso de tokenización, debes tener como resultado una lista de listas, donde cada comentario estará tokenizado por palabras.\n",
        "\n",
        "Al terminar calcula el total de tokens obtenido en todo el corpus. "
      ],
      "metadata": {
        "id": "WZwEhg2lUSAX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# leer archivo con el corpus limpio\n",
        "with open('corpus_limpio.txt', 'r') as f:\n",
        "    texto = f.read()\n",
        "\n",
        "# tokenizar por palabras\n",
        "comentarios_tokenizados = []\n",
        "for comentario in texto.split('\\n'):\n",
        "    comentario_tokenizado = word_tokenize(comentario)\n",
        "    comentarios_tokenizados.append(comentario_tokenizado)\n",
        "\n",
        "# calcular el total de tokens\n",
        "total_tokens = sum([len(comentario) for comentario in comentarios_tokenizados])\n",
        "\n",
        "# imprimir los primeros 10 comentarios tokenizados\n",
        "print(\"Primeros 10 comentarios tokenizados:\")\n",
        "for comentario in comentarios_tokenizados[:10]:\n",
        "    print(comentario)\n",
        "\n",
        "# imprimir el total de tokens\n",
        "print(\"Total de tokens: \", total_tokens)"
      ],
      "metadata": {
        "id": "kbAL9-v0V-jx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cbf736b-6fb5-4c0f-ee61-c04f5918d974"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Primeros 10 comentarios tokenizados:\n",
            "['wow', 'loved', 'this', 'place']\n",
            "['crust', 'is', 'not', 'good']\n",
            "['not', 'tasty', 'and', 'the', 'texture', 'was', 'just', 'nasty']\n",
            "['stopped', 'by', 'during', 'the', 'late', 'may', 'bank', 'holiday', 'off', 'rick', 'steve', 'recommendation', 'and', 'loved', 'it']\n",
            "['the', 'selection', 'on', 'the', 'menu', 'was', 'great', 'and', 'so', 'were', 'the', 'prices']\n",
            "['now', 'i', 'am', 'getting', 'angry', 'and', 'i', 'want', 'my', 'damn', 'pho']\n",
            "['honeslty', 'it', 'didnt', 'taste', 'that', 'fresh']\n",
            "['the', 'potatoes', 'were', 'like', 'rubber', 'and', 'you', 'could', 'tell', 'they', 'had', 'been', 'made', 'up', 'ahead', 'of', 'time', 'being', 'kept', 'under', 'a', 'warmer']\n",
            "['the', 'fries', 'were', 'great', 'too']\n",
            "['a', 'great', 'touch']\n",
            "Total de tokens:  10779\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DZs_etmiV-fd"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 15.**  \n",
        "\n",
        "Finalmente, en este ejercicio definiremos nuestro conjunto de palabras \"stopwords\", las cuales deberás eliminar de todo el corpus. \n",
        "\n",
        "Recuerda que ejemplos de stopwords son artículos, adverbios, conectivos, etcétera, que tienen frecuencias de aparición muy altas en cualquier documento, pero que no brindan mucho significado en cuanto al significado de un enunciado.\n",
        "\n",
        "Con base a la lista de stopwords que se te proporciona, realiza un proceso de limpieza eliminando todas estas palabras del corpus obtenido en el ejercicio anterior.\n",
        "\n",
        "Obtener cuántos tokens/palabras quedan finalmente en todo el corpus.\n",
        "\n",
        "Obtener cuántos de estos tokens/palabras son diferentes, es decir, cuántos tokens únicos tendrá lo que llamaremos más adelante nuestro vocabulario."
      ],
      "metadata": {
        "id": "EFeu0OJ7WDPD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Considera la siguiente lista como tu conjunto de stopwords:\n",
        "## mis_stopwords = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'should', 'now', 'll']"
      ],
      "metadata": {
        "id": "6FP4FF3KXGxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar el archivo de texto\n",
        "with open('corpus_limpio.txt', 'r', encoding='utf-8') as f:\n",
        "    corpus = f.readlines()\n",
        "\n",
        "# Tokenización por palabras del corpus\n",
        "tokenized_corpus = []\n",
        "for doc in corpus:\n",
        "    tokens = nltk.word_tokenize(doc)\n",
        "    tokenized_corpus.append(tokens)\n",
        "\n",
        "# Calcular el total de tokens en todo el corpus\n",
        "total_tokens = sum(len(tokens) for tokens in tokenized_corpus)\n",
        "\n",
        "# Guardar los resultados en un archivo de texto con formato de lista Python\n",
        "with open('corpus_tokenizado.txt', 'w', encoding='utf-8') as f:\n",
        "    f.write(str(tokenized_corpus))"
      ],
      "metadata": {
        "id": "CD8yjyq1ZrwY"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# leer archivo con tokens\n",
        "with open('corpus_tokenizado.txt', 'r') as f:\n",
        "    tokens = eval(f.read())\n",
        "\n",
        "# definir conjunto de stopwords\n",
        "mis_stopwords = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'should', 'now', 'll']\n",
        "\n",
        "# eliminar stopwords del corpus\n",
        "corpus_limpio = []\n",
        "for comentario in tokens:\n",
        "    comentario_limpio = []\n",
        "    for token in comentario:\n",
        "        if token.lower() not in mis_stopwords:\n",
        "            comentario_limpio.append(token.lower())\n",
        "    corpus_limpio.append(comentario_limpio)\n",
        "\n",
        "# calcular total de tokens\n",
        "total_tokens = 0\n",
        "for comentario in corpus_limpio:\n",
        "    total_tokens += len(comentario)\n",
        "\n",
        "# calcular cantidad de tokens únicos\n",
        "vocabulario = set()\n",
        "for comentario in corpus_limpio:\n",
        "    for token in comentario:\n",
        "        vocabulario.add(token)\n",
        "\n",
        "# imprimir resultados\n",
        "print(\"Total de tokens en el corpus limpio:\", total_tokens)\n",
        "print(\"Cantidad de tokens únicos en el corpus limpio:\", len(vocabulario))\n",
        "\n",
        "# guardar resultados en archivo de texto\n",
        "with open('corpus_final.txt', 'w') as f:\n",
        "    f.write(str(corpus_limpio))"
      ],
      "metadata": {
        "id": "4ZPi5prKZro5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ea9675e-8f7f-408c-f42b-72cda22a6351"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de tokens en el corpus limpio: 5776\n",
            "Cantidad de tokens únicos en el corpus limpio: 1940\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Comentarios**\n",
        "\n",
        "Incluye finalmente tus comentarios de la actividad."
      ],
      "metadata": {
        "id": "NDbKkuxRbLoX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta actividad crea la base para poder llevar a cabo análisis de texto más avanzados, como la identificación de temas, el análisis de sentimientos, entre otros. Es importante destacar que la limpieza y preprocesamiento de los datos son fundamentales para poder obtener resultados precisos y confiables. Así mismo, se puede concluir que se cumplieron los objetivos planteados al incio de esta actividad, ya que se logró diferenciar adecuadamente la importancia de las palabras, las frases y la gramática en un texto, además de que se aplicaron las representaciones semánticas mediante expresiones regulares y patrones de búsqueda en textos."
      ],
      "metadata": {
        "id": "o7fzbvqVbUGr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Fin de la Actividad de la semana 2.**"
      ],
      "metadata": {
        "id": "PHaKw_6Ldbaf"
      }
    }
  ]
}